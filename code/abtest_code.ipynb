{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9203c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install statsmodels\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "def analyze_experiment_results(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analyzes the results of an A/B test from a user-metrics DataFrame.\n",
    "    \"\"\"\n",
    "    control = df[df['variant_id'] == 'control']\n",
    "    treatment = df[df['variant_id'] == 'treatment']\n",
    "\n",
    "    print(f\"Analysis for Experiment: {df['experiment_id'].iloc[0]}\")\n",
    "    print(f\"Control Group Size: {len(control)}\")\n",
    "    print(f\"Treatment Group Size: {len(treatment)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 1. Analyze Conversion Rate (a binomial metric)\n",
    "    control_conversions = control['converted'].sum()\n",
    "    treatment_conversions = treatment['converted'].sum()\n",
    "    n_control = len(control)\n",
    "    n_treatment = len(treatment)\n",
    "\n",
    "    # Calculate p-value using a Z-test for proportions\n",
    "    count = np.array([treatment_conversions, control_conversions])\n",
    "    nobs = np.array([n_treatment, n_control])\n",
    "    stat, p_value_conv = proportions_ztest(count, nobs, alternative='two-sided')\n",
    "\n",
    "    # Calculate lift\n",
    "    control_rate = control_conversions / n_control\n",
    "    treatment_rate = treatment_conversions / n_treatment\n",
    "    lift_conv = (treatment_rate - control_rate) / control_rate\n",
    "\n",
    "    print(\"Metric: Conversion Rate\")\n",
    "    print(f\"Control Rate: {control_rate:.4f}\")\n",
    "    print(f\"Treatment Rate: {treatment_rate:.4f}\")\n",
    "    print(f\"Lift: {lift_conv:+.2%}\")\n",
    "    print(f\"P-value: {p_value_conv:.5f}\")\n",
    "    if p_value_conv < 0.05:\n",
    "        print(\"Result: Statistically Significant\")\n",
    "    else:\n",
    "        print(\"Result: Not Statistically Significant\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    # 2. Analyze Total Revenue (a continuous metric)\n",
    "    # We use Welch's t-test, which does not assume equal variance.\n",
    "    stat_rev, p_value_rev, dof_rev = ttest_ind(\n",
    "        treatment['total_revenue'],\n",
    "        control['total_revenue'],\n",
    "        alternative='two-sided',\n",
    "        usevar='unequal' # Welch's t-test\n",
    "    )\n",
    "\n",
    "    control_mean_rev = control['total_revenue'].mean()\n",
    "    treatment_mean_rev = treatment['total_revenue'].mean()\n",
    "    lift_rev = (treatment_mean_rev - control_mean_rev) / control_mean_rev\n",
    "\n",
    "    print(\"Metric: Total Revenue per User\")\n",
    "    print(f\"Control Mean: ${control_mean_rev:.2f}\")\n",
    "    print(f\"Treatment Mean: ${treatment_mean_rev:.2f}\")\n",
    "    print(f\"Lift: {lift_rev:+.2%}\")\n",
    "    print(f\"P-value: {p_value_rev:.5f}\")\n",
    "    if p_value_rev < 0.05:\n",
    "        print(\"Result: Statistically Significant\")\n",
    "    else:\n",
    "        print(\"Result: Not Statistically Significant\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "# In a real pipeline, this DataFrame would be loaded from your data warehouse\n",
    "# (e.g., Snowflake, BigQuery) after the dbt run is complete.\n",
    "mock_data = {\n",
    "    'user_id': [f'user_{i}' for i in range(20000)],\n",
    "    'experiment_id': ['exp-new-checkout-flow-v2'] * 20000,\n",
    "    'variant_id': ['control'] * 10000 + ['treatment'] * 10000,\n",
    "    'converted': ([1] * 1000 + [0] * 9000) + ([1] * 1050 + [0] * 8950),\n",
    "    'total_revenue': np.random.lognormal(4, 1.5, 10000).tolist() + np.random.lognormal(4.05, 1.5, 10000).tolist()\n",
    "}\n",
    "# Ensure revenue is zero for non-converters\n",
    "mock_data['total_revenue'] = [rev if conv == 1 else 0 for rev, conv in zip(mock_data['total_revenue'], mock_data['converted'])]\n",
    "\n",
    "df_results = pd.DataFrame(mock_data)\n",
    "\n",
    "# Run the analysis\n",
    "analyze_experiment_results(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
