{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f93a03",
   "metadata": {},
   "source": [
    "# Chapter 19: Deploying Experiment-Trained Models - Safe Retraining Pipelines and Governance\n",
    "\n",
    "This notebook contains all code examples from Chapter 19, demonstrating:\n",
    "\n",
    "1. **SafeExperimentRetrainer Pipeline (Section 4.2)**\n",
    "   - Temporal separation with 14-day buffer\n",
    "   - Cross-experiment validation\n",
    "   - Automated contamination checks\n",
    "\n",
    "2. **ContaminationMonitor (Section 4.3)**\n",
    "   - Holdout vs production performance tracking\n",
    "   - Distribution shift detection\n",
    "   - Alerting for degradation\n",
    "\n",
    "3. **Fairness Strategies (Section 5.1)**\n",
    "   - Strategy 1: Stratified sampling (fixes bias at source)\n",
    "   - Strategy 2: Bias auditing (detects disparate impact)\n",
    "   - Strategy 3: Fairness constraints (policy enforcement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10ed48",
   "metadata": {},
   "source": [
    "## Setup: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pandas numpy scikit-learn scipy fairlearn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9537078",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For fairness constraints (Strategy 3 in Section 5.1)\n",
    "try:\n",
    "    from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "    FAIRLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    FAIRLEARN_AVAILABLE = False\n",
    "    print(\"Warning: fairlearn not installed. Fairness constraints example will be skipped.\")\n",
    "    print(\"To install: pip install fairlearn\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb736a",
   "metadata": {},
   "source": [
    "## Generate Synthetic Experiment Data\n",
    "\n",
    "Create synthetic experiment data to demonstrate the pipeline patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiment_data(n_users=10000, n_experiments=5):\n",
    "    \"\"\"\n",
    "    Generate synthetic experiment data for demonstrating retraining pipeline.\n",
    "    \n",
    "    Args:\n",
    "        n_users: Number of unique users\n",
    "        n_experiments: Number of experiments to generate\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with experiment data including:\n",
    "        - user_id, experiment_id, treatment, outcome\n",
    "        - experiment_start_date, experiment_end_date\n",
    "        - features for model training\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    base_date = datetime(2024, 1, 1)\n",
    "    \n",
    "    for exp_id in range(1, n_experiments + 1):\n",
    "        # Each experiment runs for 2 weeks\n",
    "        exp_start = base_date + timedelta(weeks=(exp_id - 1) * 2)\n",
    "        exp_end = exp_start + timedelta(weeks=2)\n",
    "        \n",
    "        for user_id in range(n_users):\n",
    "            # User features\n",
    "            feature1 = np.random.randn()\n",
    "            feature2 = np.random.randn()\n",
    "            \n",
    "            # Treatment assignment (50/50 split)\n",
    "            treatment = np.random.choice([0, 1])\n",
    "            \n",
    "            # Outcome depends on features and treatment\n",
    "            # Simulate treatment effect\n",
    "            true_effect = 0.1  # 10% treatment effect\n",
    "            base_probability = 1 / (1 + np.exp(-(0.5 * feature1 + 0.3 * feature2)))\n",
    "            \n",
    "            if treatment == 1:\n",
    "                outcome_prob = base_probability + true_effect\n",
    "            else:\n",
    "                outcome_prob = base_probability\n",
    "            \n",
    "            outcome = np.random.binomial(1, min(outcome_prob, 1.0))\n",
    "            \n",
    "            data.append({\n",
    "                'user_id': user_id,\n",
    "                'experiment_id': exp_id,\n",
    "                'experiment_start_date': exp_start,\n",
    "                'experiment_end_date': exp_end,\n",
    "                'treatment': treatment,\n",
    "                'feature1': feature1,\n",
    "                'feature2': feature2,\n",
    "                'outcome': outcome,\n",
    "                'experiment_status': 'completed'\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Generate experiment data\n",
    "experiment_data = generate_experiment_data(n_users=1000, n_experiments=5)\n",
    "\n",
    "print(f\"Generated {len(experiment_data)} experiment records\")\n",
    "print(f\"\\nExperiments: {experiment_data['experiment_id'].nunique()}\")\n",
    "print(f\"Users: {experiment_data['user_id'].nunique()}\")\n",
    "print(f\"Date range: {experiment_data['experiment_end_date'].min()} to {experiment_data['experiment_end_date'].max()}\")\n",
    "print(\"\\nSample data:\")\n",
    "print(experiment_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa95e77",
   "metadata": {},
   "source": [
    "## Section 4.1: Mock Database for SafeExperimentRetrainer\n",
    "\n",
    "Create a simple database mock to demonstrate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e40fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockDatabase:\n",
    "    \"\"\"\n",
    "    Mock database for demonstrating SafeExperimentRetrainer.\n",
    "    In production, this would be replaced with actual database connections.\n",
    "    \"\"\"\n",
    "    def __init__(self, experiment_data, holdout_users):\n",
    "        self.experiment_data = experiment_data\n",
    "        self.holdout_users = holdout_users\n",
    "    \n",
    "    def query(self, query_string, **params):\n",
    "        \"\"\"\n",
    "        Simulate database query filtering.\n",
    "        \"\"\"\n",
    "        df = self.experiment_data.copy()\n",
    "        \n",
    "        # Filter by cutoff date\n",
    "        if 'cutoff' in params:\n",
    "            df = df[df['experiment_end_date'] < params['cutoff']]\n",
    "        \n",
    "        # Filter out holdout users\n",
    "        df = df[~df['user_id'].isin(self.holdout_users)]\n",
    "        \n",
    "        # Filter by status\n",
    "        df = df[df['experiment_status'] == 'completed']\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Create permanent holdout (5% of users)\n",
    "all_users = experiment_data['user_id'].unique()\n",
    "n_holdout = int(len(all_users) * 0.05)\n",
    "permanent_holdout_users = np.random.choice(all_users, n_holdout, replace=False)\n",
    "\n",
    "# Create mock database\n",
    "db = MockDatabase(experiment_data, permanent_holdout_users)\n",
    "\n",
    "print(f\"Mock database created with {len(experiment_data)} records\")\n",
    "print(f\"Permanent holdout: {len(permanent_holdout_users)} users ({len(permanent_holdout_users)/len(all_users)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e8990",
   "metadata": {},
   "source": [
    "## Section 4.2: SafeExperimentRetrainer Implementation\n",
    "\n",
    "Complete implementation from Chapter 19, Section 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContaminationError(Exception):\n",
    "    \"\"\"Raised when contamination risk is detected.\"\"\"\n",
    "    pass\n",
    "\n",
    "class ValidationError(Exception):\n",
    "    \"\"\"Raised when model fails validation.\"\"\"\n",
    "    pass\n",
    "\n",
    "class SafeExperimentRetrainer:\n",
    "    \"\"\"\n",
    "    Production-grade pipeline for safely retraining models on experiment data.\n",
    "    \n",
    "    Combines:\n",
    "    - Temporal separation (Pattern 1 from Section 3.1)\n",
    "    - Diverse experiment training with validation (Pattern 2 from Section 3.2)\n",
    "    - Propensity weighting (from Chapter 18)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, holdout_rate=0.05, temporal_buffer_days=14, min_acceptable_score=0.6):\n",
    "        self.holdout_rate = holdout_rate\n",
    "        self.temporal_buffer = timedelta(days=temporal_buffer_days)\n",
    "        self.min_acceptable_score = min_acceptable_score\n",
    "    \n",
    "    def get_safe_training_data(self, current_deployment_date):\n",
    "        \"\"\"\n",
    "        Retrieve experiment data that is safe to train on.\n",
    "        \n",
    "        Safety checks:\n",
    "        1. Temporal: Data must predate current deployment by buffer period\n",
    "        2. Holdout: Exclude users in permanent holdout group\n",
    "        3. Completeness: Experiments must have fully ended\n",
    "        \"\"\"\n",
    "        cutoff_date = current_deployment_date - self.temporal_buffer\n",
    "        \n",
    "        # Query database (in production this would be SQL query)\n",
    "        data = db.query(\"\"\"\n",
    "            SELECT * FROM experiments\n",
    "            WHERE experiment_end_date < :cutoff\n",
    "            AND user_id NOT IN (SELECT user_id FROM permanent_holdout)\n",
    "            AND experiment_status = 'completed'\n",
    "        \"\"\", cutoff=cutoff_date)\n",
    "        \n",
    "        # Validation\n",
    "        self._validate_temporal_safety(data, current_deployment_date)\n",
    "        self._validate_no_future_leakage(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _validate_temporal_safety(self, data, deployment_date):\n",
    "        \"\"\"Ensure no data postdates deployment.\"\"\"\n",
    "        if len(data) == 0:\n",
    "            raise ContaminationError(\"No training data available after temporal filtering.\")\n",
    "        \n",
    "        max_date = data['experiment_end_date'].max()\n",
    "        buffer_date = deployment_date - self.temporal_buffer\n",
    "        \n",
    "        if max_date >= buffer_date:\n",
    "            raise ContaminationError(\n",
    "                f\"Training data includes recent experiments: \"\n",
    "                f\"{max_date} >= {buffer_date}. \"\n",
    "                f\"Risk of feedback loops.\"\n",
    "            )\n",
    "    \n",
    "    def _validate_no_future_leakage(self, data):\n",
    "        \"\"\"Check for suspicious patterns indicating contamination.\"\"\"\n",
    "        # Example: Check if treatment effects are suspiciously large\n",
    "        treatment_means = data.groupby('treatment')['outcome'].mean()\n",
    "        if len(treatment_means) < 2:\n",
    "            return\n",
    "        \n",
    "        ate = treatment_means.diff().iloc[-1]\n",
    "        \n",
    "        if ate > 0.5:  # Threshold based on domain knowledge\n",
    "            warnings.warn(\n",
    "                f\"Unusually large treatment effect ({ate:.2%}). \"\n",
    "                f\"Possible contamination or cherry-picked experiments.\"\n",
    "            )\n",
    "    \n",
    "    def retrain_with_validation(self, model, current_deployment_date):\n",
    "        \"\"\"\n",
    "        Retrain model with counterfactual cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            model: Scikit-learn compatible model with fit/score methods\n",
    "            current_deployment_date: Current date for temporal filtering\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (trained_model, validation_score)\n",
    "        \"\"\"\n",
    "        # Get safe training data\n",
    "        all_data = self.get_safe_training_data(current_deployment_date)\n",
    "        \n",
    "        print(f\"Retrieved {len(all_data)} safe training records\")\n",
    "        print(f\"Experiments used: {sorted(all_data['experiment_id'].unique())}\")\n",
    "        \n",
    "        # Split by experiment ID (not users) - implements Pattern 2 from Section 3.2\n",
    "        experiment_ids = all_data['experiment_id'].unique()\n",
    "        np.random.shuffle(experiment_ids)\n",
    "        \n",
    "        train_exp_ids = experiment_ids[:len(experiment_ids)//2]\n",
    "        val_exp_ids = experiment_ids[len(experiment_ids)//2:]\n",
    "        \n",
    "        train_data = all_data[all_data['experiment_id'].isin(train_exp_ids)]\n",
    "        val_data = all_data[all_data['experiment_id'].isin(val_exp_ids)]\n",
    "        \n",
    "        print(f\"\\nTrain experiments: {sorted(train_exp_ids)}\")\n",
    "        print(f\"Validation experiments: {sorted(val_exp_ids)}\")\n",
    "        print(f\"Train samples: {len(train_data)}, Validation samples: {len(val_data)}\")\n",
    "        \n",
    "        # Prepare features and labels\n",
    "        X_train = train_data[['feature1', 'feature2']]\n",
    "        y_train = train_data['outcome']\n",
    "        \n",
    "        X_val = val_data[['feature1', 'feature2']]\n",
    "        y_val = val_data['outcome']\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Validate on separate experiments\n",
    "        val_score = model.score(X_val, y_val)\n",
    "        \n",
    "        print(f\"\\nCross-experiment validation score: {val_score:.3f}\")\n",
    "        \n",
    "        if val_score < self.min_acceptable_score:\n",
    "            raise ValidationError(\n",
    "                f\"Model fails cross-experiment validation: {val_score:.3f} < {self.min_acceptable_score}\"\n",
    "            )\n",
    "        \n",
    "        return model, val_score\n",
    "\n",
    "print(\"SafeExperimentRetrainer class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742c642",
   "metadata": {},
   "source": [
    "## Section 4.2: Demonstrate SafeExperimentRetrainer Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63391a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retrainer\n",
    "retrainer = SafeExperimentRetrainer(holdout_rate=0.05, temporal_buffer_days=14, min_acceptable_score=0.5)\n",
    "\n",
    "# Create a simple model\n",
    "my_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Simulate current deployment date (4 weeks after last experiment)\n",
    "latest_exp_date = experiment_data['experiment_end_date'].max()\n",
    "current_date = latest_exp_date + timedelta(weeks=4)\n",
    "\n",
    "print(f\"Current deployment date: {current_date}\")\n",
    "print(f\"Temporal buffer: 14 days\")\n",
    "print(f\"Will use experiments ending before: {current_date - timedelta(days=14)}\\n\")\n",
    "\n",
    "try:\n",
    "    new_model, val_score = retrainer.retrain_with_validation(\n",
    "        model=my_model,\n",
    "        current_deployment_date=current_date\n",
    "    )\n",
    "    print(f\"\\n✅ Retraining successful! Validation score: {val_score:.3f}\")\n",
    "except ContaminationError as e:\n",
    "    print(f\"\\n❌ Training aborted due to contamination risk: {e}\")\n",
    "except ValidationError as e:\n",
    "    print(f\"\\n❌ Training aborted due to validation failure: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fda4ec",
   "metadata": {},
   "source": [
    "## Section 4.3: ContaminationMonitor Implementation\n",
    "\n",
    "Post-deployment monitoring from Chapter 19, Section 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b11cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContaminationMonitor:\n",
    "    \"\"\"\n",
    "    Monitor deployed models for signs of contamination in production.\n",
    "    Compares production (95%) vs permanent holdout (5%) performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def check_holdout_vs_production(self, holdout_metrics, production_metrics):\n",
    "        \"\"\"\n",
    "        Compare holdout vs production performance at current point in time.\n",
    "        \n",
    "        Expected: Production (trained ML model) should outperform holdout (baseline)\n",
    "        Red flag: Production underperforms holdout → model learned patterns that don't work\n",
    "        \"\"\"\n",
    "        holdout_conversion = holdout_metrics['conversion_rate']\n",
    "        prod_conversion = production_metrics['conversion_rate']\n",
    "        \n",
    "        print(f\"Holdout (baseline V0) conversion: {holdout_conversion:.3f}\")\n",
    "        print(f\"Production (ML model) conversion: {prod_conversion:.3f}\")\n",
    "        \n",
    "        # Production should be better than holdout (or at worst, equal)\n",
    "        if prod_conversion < holdout_conversion:\n",
    "            degradation = (holdout_conversion - prod_conversion) / holdout_conversion\n",
    "            self.alert(\n",
    "                f\"CONTAMINATION: Production underperforms holdout by {degradation:.1%}. \"\n",
    "                f\"Holdout (baseline): {holdout_conversion:.3f}, \"\n",
    "                f\"Production (ML model): {prod_conversion:.3f}. \"\n",
    "                f\"Model is worse than doing nothing!\"\n",
    "            )\n",
    "        else:\n",
    "            improvement = (prod_conversion - holdout_conversion) / holdout_conversion\n",
    "            print(f\"✅ Production outperforms holdout by {improvement:.1%}\")\n",
    "    \n",
    "    def check_distribution_shift(self, training_features, production_features):\n",
    "        \"\"\"\n",
    "        Detect if production data distribution diverges from training data.\n",
    "        \n",
    "        Red flag: Large distribution shifts may indicate the model is changing\n",
    "        user behavior in unexpected ways (contamination feedback loop).\n",
    "        \"\"\"\n",
    "        print(\"\\nChecking distribution shift...\")\n",
    "        \n",
    "        for feature in training_features.columns:\n",
    "            stat, p_value = ks_2samp(\n",
    "                training_features[feature], \n",
    "                production_features[feature]\n",
    "            )\n",
    "            \n",
    "            print(f\"  {feature}: KS statistic={stat:.3f}, p-value={p_value:.4f}\", end=\"\")\n",
    "            \n",
    "            if p_value < 0.01:\n",
    "                print(\" ⚠️\")\n",
    "                self.alert(\n",
    "                    f\"Distribution shift detected in '{feature}' \"\n",
    "                    f\"(KS statistic: {stat:.3f}, p-value: {p_value:.4f}). \"\n",
    "                    f\"Model may be influencing user behavior.\"\n",
    "                )\n",
    "            else:\n",
    "                print(\" ✅\")\n",
    "    \n",
    "    def alert(self, message):\n",
    "        \"\"\"Send alert to on-call team.\"\"\"\n",
    "        print(f\"\\n[ALERT] {message}\")\n",
    "        # In production: Send to PagerDuty, Slack, email, etc.\n",
    "\n",
    "print(\"ContaminationMonitor class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349eecf2",
   "metadata": {},
   "source": [
    "## Section 4.3: Demonstrate ContaminationMonitor Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic production data\n",
    "def generate_production_data(n_samples=1000, distribution_shift=False):\n",
    "    \"\"\"Generate synthetic production data for monitoring.\"\"\"\n",
    "    if distribution_shift:\n",
    "        # Simulate distribution shift (contamination)\n",
    "        feature1 = np.random.randn(n_samples) + 0.5  # Shifted mean\n",
    "        feature2 = np.random.randn(n_samples) * 1.5  # Changed variance\n",
    "    else:\n",
    "        # No shift (healthy)\n",
    "        feature1 = np.random.randn(n_samples)\n",
    "        feature2 = np.random.randn(n_samples)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'feature1': feature1,\n",
    "        'feature2': feature2\n",
    "    })\n",
    "\n",
    "# Create monitor\n",
    "monitor = ContaminationMonitor()\n",
    "\n",
    "# Scenario 1: Healthy system (production outperforms holdout, no distribution shift)\n",
    "print(\"=\" * 60)\n",
    "print(\"Scenario 1: Healthy System\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "holdout_metrics = {'conversion_rate': 0.15}  # Baseline\n",
    "production_metrics = {'conversion_rate': 0.18}  # ML model improved\n",
    "\n",
    "monitor.check_holdout_vs_production(holdout_metrics, production_metrics)\n",
    "\n",
    "# Check distribution (no shift)\n",
    "training_features = experiment_data[['feature1', 'feature2']].sample(1000)\n",
    "production_features = generate_production_data(1000, distribution_shift=False)\n",
    "\n",
    "monitor.check_distribution_shift(training_features, production_features)\n",
    "\n",
    "# Scenario 2: Contaminated system (production underperforms, distribution shift)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Scenario 2: Contaminated System\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "holdout_metrics = {'conversion_rate': 0.15}  # Baseline\n",
    "production_metrics = {'conversion_rate': 0.12}  # ML model degraded!\n",
    "\n",
    "monitor.check_holdout_vs_production(holdout_metrics, production_metrics)\n",
    "\n",
    "# Check distribution (with shift)\n",
    "production_features_shifted = generate_production_data(1000, distribution_shift=True)\n",
    "\n",
    "monitor.check_distribution_shift(training_features, production_features_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabbe9a",
   "metadata": {},
   "source": [
    "## Section 5.1: Stratified Sampling for Fairness (Strategy 1)\n",
    "\n",
    "From Chapter 19, Section 5.1 - ensures experiment data is representative across demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2225e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_to_experiment_with_stratification(users, strata_columns):\n",
    "    \"\"\"\n",
    "    Assign users to experiment with stratified sampling.\n",
    "    Ensures each demographic group is proportionally represented.\n",
    "    \n",
    "    Args:\n",
    "        users: DataFrame with user attributes\n",
    "        strata_columns: List of columns to stratify by (e.g., ['location_type', 'industry'])\n",
    "    \n",
    "    Returns:\n",
    "        users with 'in_experiment' flag\n",
    "    \"\"\"\n",
    "    # Create stratification key combining all strata\n",
    "    users['strata_key'] = users[strata_columns].astype(str).agg('_'.join, axis=1)\n",
    "    \n",
    "    # Split into experiment (50%) and holdout (50%), stratified by demographics\n",
    "    experiment_users, _ = train_test_split(\n",
    "        users,\n",
    "        test_size=0.5,\n",
    "        stratify=users['strata_key'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    users['in_experiment'] = users.index.isin(experiment_users.index)\n",
    "    \n",
    "    # Verify stratification worked\n",
    "    print(\"Population distribution:\")\n",
    "    pop_dist = users['strata_key'].value_counts(normalize=True).sort_index()\n",
    "    print(pop_dist)\n",
    "    \n",
    "    print(\"\\nExperiment distribution:\")\n",
    "    exp_dist = users[users['in_experiment']]['strata_key'].value_counts(normalize=True).sort_index()\n",
    "    print(exp_dist)\n",
    "    \n",
    "    # Calculate maximum difference\n",
    "    max_diff = (pop_dist - exp_dist).abs().max()\n",
    "    print(f\"\\nMaximum distribution difference: {max_diff:.4f}\")\n",
    "    \n",
    "    return users\n",
    "\n",
    "# Example: Job recommendation experiment\n",
    "users = pd.DataFrame({\n",
    "    'user_id': range(10000),\n",
    "    'location_type': np.random.choice(['tech_hub', 'non_tech_hub'], 10000, p=[0.3, 0.7]),\n",
    "    'industry': np.random.choice(['tech', 'healthcare', 'finance', 'retail'], 10000)\n",
    "})\n",
    "\n",
    "# Ensure experiment includes proportional representation\n",
    "users = assign_to_experiment_with_stratification(\n",
    "    users, \n",
    "    strata_columns=['location_type', 'industry']\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Result: Experiment data will be representative across location_type × industry combinations\")\n",
    "print(f\"Training a model on this data reduces bias compared to convenience sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafd389",
   "metadata": {},
   "source": [
    "## Section 5.1: Bias Auditing Before Deployment (Strategy 2)\n",
    "\n",
    "Measure model performance across subgroups to detect disparate impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb845101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic validation data with location groups\n",
    "np.random.seed(42)\n",
    "validation_data = pd.DataFrame({\n",
    "    'feature1': np.random.randn(1000),\n",
    "    'feature2': np.random.randn(1000),\n",
    "    'location': np.random.choice(['tech_hub', 'non_tech_hub'], 1000, p=[0.3, 0.7])\n",
    "})\n",
    "\n",
    "# Generate outcomes (tech_hub has higher conversion)\n",
    "validation_data['outcome'] = (\n",
    "    (validation_data['feature1'] + validation_data['feature2'] > 0).astype(int)\n",
    ")\n",
    "\n",
    "# Add location bias (tech_hub users more likely to convert)\n",
    "tech_hub_mask = validation_data['location'] == 'tech_hub'\n",
    "validation_data.loc[tech_hub_mask, 'outcome'] = (\n",
    "    (validation_data.loc[tech_hub_mask, 'outcome'] | (np.random.rand(tech_hub_mask.sum()) > 0.3)).astype(int)\n",
    ")\n",
    "\n",
    "# Train a simple model\n",
    "model = LogisticRegression(random_state=42)\n",
    "X = validation_data[['feature1', 'feature2']]\n",
    "y = validation_data['outcome']\n",
    "model.fit(X, y)\n",
    "\n",
    "# Check model performance across demographic groups\n",
    "print(\"Bias Auditing: Model Performance Across Groups\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "min_acceptable_score = 0.55\n",
    "\n",
    "for group in ['tech_hub', 'non_tech_hub']:\n",
    "    group_data = validation_data[validation_data['location'] == group]\n",
    "    X_group = group_data[['feature1', 'feature2']]\n",
    "    y_group = group_data['outcome']\n",
    "    \n",
    "    group_score = model.score(X_group, y_group)\n",
    "    print(f\"{group}: Accuracy = {group_score:.3f}\", end=\"\")\n",
    "    \n",
    "    if group_score < min_acceptable_score:\n",
    "        print(f\" ❌ BELOW THRESHOLD ({min_acceptable_score})\")\n",
    "        print(f\"   [ERROR] Model underperforms on {group}\")\n",
    "    else:\n",
    "        print(f\" ✅\")\n",
    "\n",
    "# Calculate disparate impact\n",
    "tech_score = model.score(\n",
    "    validation_data[validation_data['location'] == 'tech_hub'][['feature1', 'feature2']],\n",
    "    validation_data[validation_data['location'] == 'tech_hub']['outcome']\n",
    ")\n",
    "non_tech_score = model.score(\n",
    "    validation_data[validation_data['location'] == 'non_tech_hub'][['feature1', 'feature2']],\n",
    "    validation_data[validation_data['location'] == 'non_tech_hub']['outcome']\n",
    ")\n",
    "\n",
    "disparate_impact = non_tech_score / tech_score if tech_score > 0 else 0\n",
    "print(f\"\\nDisparate Impact Ratio: {disparate_impact:.3f}\")\n",
    "print(f\"  (Ratio of non_tech_hub / tech_hub performance)\")\n",
    "print(f\"  Ideal: 1.0 (equal performance), Concerning: <0.8 (80% rule)\")\n",
    "\n",
    "if disparate_impact < 0.8:\n",
    "    print(f\"  ⚠️ WARNING: Model shows potential bias against non_tech_hub users\")\n",
    "else:\n",
    "    print(f\"  ✅ Model performance is reasonably balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9f2a4",
   "metadata": {},
   "source": [
    "## Section 5.1: Fairness Constraints During Training (Strategy 3)\n",
    "\n",
    "**IMPORTANT**: This strategy imposes policy constraints on the model, which may reduce performance.\n",
    "Use only when you have a policy requirement for equal treatment across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAIRLEARN_AVAILABLE:\n",
    "    print(\"Fairness Constraints: Enforcing Demographic Parity\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nScenario: Job recommendation data shows different acceptance rates by location\")\n",
    "    print(\"Question: Is this difference due to:\")\n",
    "    print(\"  A) Tech hub users genuinely prefer different jobs (legitimate pattern)\")\n",
    "    print(\"  B) Your experiment had biased job offerings (data collection problem)\")\n",
    "    print(\"\\nFairness constraints assume B and enforce equal treatment.\\n\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train = validation_data[['feature1', 'feature2']]\n",
    "    y_train = validation_data['outcome']\n",
    "    sensitive_features = validation_data['location']\n",
    "    \n",
    "    # Train unconstrained model\n",
    "    unconstrained_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)\n",
    "    unconstrained_model.fit(X_train, y_train)\n",
    "    unconstrained_accuracy = unconstrained_model.score(X_train, y_train)\n",
    "    \n",
    "    # Calculate unconstrained selection rates by group\n",
    "    predictions_unconstrained = unconstrained_model.predict(X_train)\n",
    "    tech_rate_unconstrained = predictions_unconstrained[sensitive_features == 'tech_hub'].mean()\n",
    "    non_tech_rate_unconstrained = predictions_unconstrained[sensitive_features == 'non_tech_hub'].mean()\n",
    "    \n",
    "    print(f\"Unconstrained Model:\")\n",
    "    print(f\"  Overall Accuracy: {unconstrained_accuracy:.3f}\")\n",
    "    print(f\"  Tech hub selection rate: {tech_rate_unconstrained:.3f}\")\n",
    "    print(f\"  Non-tech hub selection rate: {non_tech_rate_unconstrained:.3f}\")\n",
    "    print(f\"  Difference: {abs(tech_rate_unconstrained - non_tech_rate_unconstrained):.3f}\\n\")\n",
    "    \n",
    "    # Train with fairness constraints\n",
    "    constraint = DemographicParity()  # Policy: Equal recommendation rates across groups\n",
    "    mitigator = ExponentiatedGradient(\n",
    "        estimator=RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5),\n",
    "        constraints=constraint\n",
    "    )\n",
    "    \n",
    "    # This enforces: P(recommend job | tech_hub) ≈ P(recommend job | non_tech_hub)\n",
    "    # Regardless of what the data shows about actual acceptance rates\n",
    "    mitigator.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        sensitive_features=sensitive_features\n",
    "    )\n",
    "    \n",
    "    # Evaluate constrained model\n",
    "    predictions_constrained = mitigator.predict(X_train)\n",
    "    constrained_accuracy = (predictions_constrained == y_train).mean()\n",
    "    tech_rate_constrained = predictions_constrained[sensitive_features == 'tech_hub'].mean()\n",
    "    non_tech_rate_constrained = predictions_constrained[sensitive_features == 'non_tech_hub'].mean()\n",
    "    \n",
    "    print(f\"Constrained Model (Demographic Parity):\")\n",
    "    print(f\"  Overall Accuracy: {constrained_accuracy:.3f}\")\n",
    "    print(f\"  Tech hub selection rate: {tech_rate_constrained:.3f}\")\n",
    "    print(f\"  Non-tech hub selection rate: {non_tech_rate_constrained:.3f}\")\n",
    "    print(f\"  Difference: {abs(tech_rate_constrained - non_tech_rate_constrained):.3f}\\n\")\n",
    "    \n",
    "    # Show trade-off\n",
    "    accuracy_loss = unconstrained_accuracy - constrained_accuracy\n",
    "    fairness_gain = abs(tech_rate_unconstrained - non_tech_rate_unconstrained) - abs(tech_rate_constrained - non_tech_rate_constrained)\n",
    "    \n",
    "    print(f\"Trade-off:\")\n",
    "    print(f\"  Accuracy loss: {accuracy_loss:.3f} ({accuracy_loss/unconstrained_accuracy*100:.1f}%)\")\n",
    "    print(f\"  Fairness gain (reduced disparity): {fairness_gain:.3f}\\n\")\n",
    "    \n",
    "    print(\"Critical Questions Before Using This:\")\n",
    "    print(\"1. Is the data difference due to bias or reality?\")\n",
    "    print(\"2. Is this social engineering? (Yes, explicitly)\")\n",
    "    print(\"3. What's the cost? (Lower model performance)\")\n",
    "    print(\"\\nRecommendation: Use Strategy 1 (Stratified Sampling) to fix bias at source.\")\n",
    "    print(\"Only use Strategy 3 when you have a policy requirement for equal treatment.\")\n",
    "else:\n",
    "    print(\"Fairlearn not available. Skipping fairness constraints example.\")\n",
    "    print(\"To run this example: pip install fairlearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c777d",
   "metadata": {},
   "source": [
    "## Visualization: Timeline of Safe Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the temporal separation pattern\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Timeline data\n",
    "weeks = np.arange(1, 11)\n",
    "events = [\n",
    "    (1, \"Deploy V0\\nRun Exp 1 (V0)\", 'green'),\n",
    "    (3, \"Deploy V1\\nRun Exp 2 (V1)\", 'blue'),\n",
    "    (5, \"Deploy V2\\nRun Exp 3 (V2)\", 'blue'),\n",
    "    (7, \"Train V3 on Exp 1 data\\nDeploy V3, Run Exp 4\", 'green'),\n",
    "    (9, \"Train V4 on Exp 2 data\\nDeploy V4\", 'green'),\n",
    "]\n",
    "\n",
    "# Plot timeline\n",
    "ax.axhline(y=0, color='black', linewidth=2)\n",
    "\n",
    "for week, event, color in events:\n",
    "    ax.plot(week, 0, 'o', markersize=15, color=color)\n",
    "    ax.text(week, 0.3, event, ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round', facecolor=color, alpha=0.3))\n",
    "\n",
    "# Add annotations\n",
    "ax.annotate('', xy=(7, -0.5), xytext=(1, -0.5),\n",
    "            arrowprops=dict(arrowstyle='<->', color='red', lw=2))\n",
    "ax.text(4, -0.7, 'V3 trains on V0 data\\n(2 generations back)', \n",
    "        ha='center', fontsize=10, color='red', weight='bold')\n",
    "\n",
    "ax.set_xlim(0, 11)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_xlabel('Week', fontsize=12)\n",
    "ax.set_title('Temporal Separation Pattern (Version Skipping)\\nPrevents Feedback Loops', \n",
    "             fontsize=14, weight='bold')\n",
    "ax.set_yticks([])\n",
    "ax.grid(True, axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key insight: Model V3 trains on data from V0 (not V2), breaking the contamination chain.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
