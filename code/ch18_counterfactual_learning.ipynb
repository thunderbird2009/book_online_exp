{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c997054a",
   "metadata": {},
   "source": [
    "# Chapter 18: Machine Learning from Experiment - Counterfactual Learning\n",
    "\n",
    "This notebook contains all code examples from Chapter 18, demonstrating counterfactual learning methods for training ML models from experiment data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd160b",
   "metadata": {},
   "source": [
    "## Setup: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pandas numpy scikit-learn econml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af7fb5",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b94140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57197be1",
   "metadata": {},
   "source": [
    "## Section 2.2.4: Instrumental Variables (IV)\n",
    "\n",
    "Using clean control data to correct contaminated production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e66f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ econml not installed. Install with: pip install econml\n",
      "This is an advanced method - skipping for basic demo\n"
     ]
    }
   ],
   "source": [
    "# Note: This example requires econml library\n",
    "# The IV method uses control data to debias production data\n",
    "\n",
    "try:\n",
    "    from econml.iv.dml import DMLIV\n",
    "    \n",
    "    def train_with_iv_correction(control_data, production_data):\n",
    "        \"\"\"\n",
    "        Use clean control data to correct contaminated production data.\n",
    "        \n",
    "        Args:\n",
    "            control_data: Small dataset with random assignments (unbiased)\n",
    "            production_data: Large dataset with model-influenced assignments (biased)\n",
    "        \"\"\"\n",
    "        # Create instrument: 1 for random assignment, 0 for model assignment\n",
    "        control_data['instrument'] = 1\n",
    "        production_data['instrument'] = 0\n",
    "        combined_data = pd.concat([control_data, production_data])\n",
    "        \n",
    "        X = combined_data[['user_age', 'song_genre', 'time_of_day']]\n",
    "        Y = combined_data['engagement']\n",
    "        T = combined_data['song_shown']  # Treatment (which song shown)\n",
    "        Z = combined_data['instrument']  # Instrument (random vs model)\n",
    "        \n",
    "        # Train IV model using control data to debias production data\n",
    "        iv_model = DMLIV(\n",
    "            model_y_xw=RandomForestRegressor(),\n",
    "            model_t_xw=RandomForestRegressor(),\n",
    "            model_t_xwz=RandomForestRegressor(),\n",
    "            discrete_treatment=False\n",
    "        )\n",
    "        \n",
    "        iv_model.fit(Y, T, X=X, Z=Z)\n",
    "        return iv_model\n",
    "    \n",
    "    print(\"✓ IV function defined successfully\")\n",
    "    print(\"Note: Requires control_data and production_data to run\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠ econml not installed. Install with: pip install econml\")\n",
    "    print(\"This is an advanced method - skipping for basic demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252774d",
   "metadata": {},
   "source": [
    "## Section 2.3: Use Case 1 - Personalized Recommendations\n",
    "\n",
    "### Step 1: Collect Experiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5af4c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Data:\n",
      "   user_id  age  num_past_purchases  treatment   ctr\n",
      "0        1   25                   2          1  0.08\n",
      "1        2   34                  10          0  0.05\n",
      "2        3   45                   0          1  0.03\n",
      "3        4   29                   5          0  0.06\n",
      "4        5   52                  15          1  0.12\n",
      "5        6   38                   3          0  0.04\n",
      "\n",
      "Treatment group size: 3\n",
      "Control group size: 3\n"
     ]
    }
   ],
   "source": [
    "# Experiment data: (user_features, treatment, CTR)\n",
    "experiment_data = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4, 5, 6],\n",
    "    'age': [25, 34, 45, 29, 52, 38],\n",
    "    'num_past_purchases': [2, 10, 0, 5, 15, 3],\n",
    "    'treatment': [1, 0, 1, 0, 1, 0],  # 1=personalized, 0=popular\n",
    "    'ctr': [0.08, 0.05, 0.03, 0.06, 0.12, 0.04]\n",
    "})\n",
    "\n",
    "print(\"Experiment Data:\")\n",
    "print(experiment_data)\n",
    "print(f\"\\nTreatment group size: {(experiment_data['treatment'] == 1).sum()}\")\n",
    "print(f\"Control group size: {(experiment_data['treatment'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0678d",
   "metadata": {},
   "source": [
    "### Step 2: Train a Counterfactual Model (T-Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc379e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ T-Learner models trained successfully\n",
      "  Treatment model: 3 samples\n",
      "  Control model: 3 samples\n"
     ]
    }
   ],
   "source": [
    "# Separate treatment and control data\n",
    "treatment_data = experiment_data[experiment_data['treatment'] == 1]\n",
    "control_data = experiment_data[experiment_data['treatment'] == 0]\n",
    "\n",
    "X_features = ['age', 'num_past_purchases']\n",
    "\n",
    "# Train two models\n",
    "model_treatment = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_treatment.fit(treatment_data[X_features], treatment_data['ctr'])\n",
    "\n",
    "model_control = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_control.fit(control_data[X_features], control_data['ctr'])\n",
    "\n",
    "print(\"✓ T-Learner models trained successfully\")\n",
    "print(f\"  Treatment model: {len(treatment_data)} samples\")\n",
    "print(f\"  Control model: {len(control_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a0a40",
   "metadata": {},
   "source": [
    "### Step 3: Predict Individual Treatment Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ccde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted CTR (personalized): 0.0696\n",
      "Predicted CTR (popular): 0.0563\n",
      "Expected uplift: 0.0133\n",
      "\n",
      "✓ Recommend: Personalized\n"
     ]
    }
   ],
   "source": [
    "# For a new user, predict CTR under both scenarios\n",
    "new_user = pd.DataFrame({'age': [30], 'num_past_purchases': [7]})\n",
    "\n",
    "ctr_personalized = model_treatment.predict(new_user)[0]\n",
    "ctr_popular = model_control.predict(new_user)[0]\n",
    "\n",
    "uplift = ctr_personalized - ctr_popular\n",
    "print(f\"Predicted CTR (personalized): {ctr_personalized:.4f}\")\n",
    "print(f\"Predicted CTR (popular): {ctr_popular:.4f}\")\n",
    "print(f\"Expected uplift: {uplift:.4f}\")\n",
    "\n",
    "# Decision rule: Show personalized recommendations if uplift > threshold\n",
    "if uplift > 0.01:\n",
    "    print(\"\\n✓ Recommend: Personalized\")\n",
    "else:\n",
    "    print(\"\\n✓ Recommend: Popular\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d27ef4",
   "metadata": {},
   "source": [
    "### Step 3b: Adding Uncertainty Estimates\n",
    "\n",
    "#### Method 1: Using Random Forest's Built-in Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ed6a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random Forest uncertainty function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_with_uncertainty_rf(model, X):\n",
    "    \"\"\"\n",
    "    Use Random Forest's ensemble of trees to estimate uncertainty.\n",
    "    \n",
    "    Returns:\n",
    "        mean: Point prediction (average across trees)\n",
    "        std: Standard error (variance across trees)\n",
    "        ci_lower, ci_upper: 95% confidence interval\n",
    "    \"\"\"\n",
    "    # Get predictions from each tree in the forest\n",
    "    tree_predictions = np.array([tree.predict(X) for tree in model.estimators_])\n",
    "    \n",
    "    mean_pred = tree_predictions.mean(axis=0)[0]\n",
    "    std_pred = tree_predictions.std(axis=0)[0]\n",
    "    \n",
    "    # 95% confidence interval\n",
    "    ci_lower = np.percentile(tree_predictions, 2.5, axis=0)[0]\n",
    "    ci_upper = np.percentile(tree_predictions, 97.5, axis=0)[0]\n",
    "    \n",
    "    return mean_pred, std_pred, ci_lower, ci_upper\n",
    "\n",
    "print(\"✓ Random Forest uncertainty function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39146969",
   "metadata": {},
   "source": [
    "#### Method 2: Bootstrap Resampling (More Robust for Small Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f2c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bootstrap uncertainty function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_with_bootstrap(model_class, X_train, y_train, X_test, n_bootstrap=100):\n",
    "    \"\"\"\n",
    "    Bootstrap the training data to estimate prediction uncertainty.\n",
    "    \n",
    "    Args:\n",
    "        model_class: Model class to instantiate (e.g., RandomForestRegressor)\n",
    "        X_train, y_train: Training data\n",
    "        X_test: Test data for prediction\n",
    "        n_bootstrap: Number of bootstrap resamples (typically 50-200)\n",
    "        \n",
    "    Returns:\n",
    "        mean, std, ci_lower, ci_upper\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample training data with replacement\n",
    "        X_boot, y_boot = resample(X_train, y_train, random_state=i)\n",
    "        \n",
    "        # Train model on bootstrap sample\n",
    "        model = model_class(n_estimators=50, random_state=i)\n",
    "        model.fit(X_boot, y_boot)\n",
    "        \n",
    "        # Predict on test data\n",
    "        pred = model.predict(X_test)[0]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    mean_pred = predictions.mean()\n",
    "    std_pred = predictions.std()\n",
    "    ci_lower = np.percentile(predictions, 2.5)\n",
    "    ci_upper = np.percentile(predictions, 97.5)\n",
    "    \n",
    "    return mean_pred, std_pred, ci_lower, ci_upper\n",
    "\n",
    "print(\"✓ Bootstrap uncertainty function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0f7b1",
   "metadata": {},
   "source": [
    "#### Apply Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ba172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bootstrap method (n=100 resamples)...\n",
      "\n",
      "✓ Uncertainty estimates computed\n",
      "\n",
      "✓ Uncertainty estimates computed\n"
     ]
    }
   ],
   "source": [
    "# Choose method based on data size\n",
    "if len(treatment_data) < 1000:\n",
    "    # Use bootstrap for small datasets (more accurate uncertainty)\n",
    "    print(\"Using bootstrap method (n=100 resamples)...\")\n",
    "    ctr_pers_mean, ctr_pers_std, ctr_pers_lower, ctr_pers_upper = \\\n",
    "        predict_with_bootstrap(\n",
    "            RandomForestRegressor,\n",
    "            treatment_data[X_features], \n",
    "            treatment_data['ctr'],\n",
    "            new_user,\n",
    "            n_bootstrap=100\n",
    "        )\n",
    "    \n",
    "    ctr_pop_mean, ctr_pop_std, ctr_pop_lower, ctr_pop_upper = \\\n",
    "        predict_with_bootstrap(\n",
    "            RandomForestRegressor,\n",
    "            control_data[X_features],\n",
    "            control_data['ctr'],\n",
    "            new_user,\n",
    "            n_bootstrap=100\n",
    "        )\n",
    "else:\n",
    "    # Use RF built-in for large datasets (faster)\n",
    "    print(\"Using Random Forest built-in uncertainty...\")\n",
    "    ctr_pers_mean, ctr_pers_std, ctr_pers_lower, ctr_pers_upper = \\\n",
    "        predict_with_uncertainty_rf(model_treatment, new_user)\n",
    "    \n",
    "    ctr_pop_mean, ctr_pop_std, ctr_pop_lower, ctr_pop_upper = \\\n",
    "        predict_with_uncertainty_rf(model_control, new_user)\n",
    "\n",
    "print(\"\\n✓ Uncertainty estimates computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d68e9",
   "metadata": {},
   "source": [
    "#### Computing Uplift with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d5206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted CTR (personalized): 0.0695 ± 0.0205\n",
      "  95% CI: [0.0300, 0.1200]\n",
      "\n",
      "Predicted CTR (popular): 0.0546 ± 0.0052\n",
      "  95% CI: [0.0400, 0.0600]\n",
      "\n",
      "Expected uplift: 0.0150 ± 0.0211\n",
      "  95% CI: [-0.0300, 0.0800]\n"
     ]
    }
   ],
   "source": [
    "# Uplift uncertainty (using variance propagation)\n",
    "uplift_mean = ctr_pers_mean - ctr_pop_mean\n",
    "uplift_std = np.sqrt(ctr_pers_std**2 + ctr_pop_std**2)\n",
    "uplift_lower = ctr_pers_lower - ctr_pop_upper  # Conservative bound\n",
    "uplift_upper = ctr_pers_upper - ctr_pop_lower\n",
    "\n",
    "print(f\"\\nPredicted CTR (personalized): {ctr_pers_mean:.4f} ± {ctr_pers_std:.4f}\")\n",
    "print(f\"  95% CI: [{ctr_pers_lower:.4f}, {ctr_pers_upper:.4f}]\")\n",
    "print(f\"\\nPredicted CTR (popular): {ctr_pop_mean:.4f} ± {ctr_pop_std:.4f}\")\n",
    "print(f\"  95% CI: [{ctr_pop_lower:.4f}, {ctr_pop_upper:.4f}]\")\n",
    "print(f\"\\nExpected uplift: {uplift_mean:.4f} ± {uplift_std:.4f}\")\n",
    "print(f\"  95% CI: [{uplift_lower:.4f}, {uplift_upper:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c49e0",
   "metadata": {},
   "source": [
    "#### Risk-Aware Decision Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2accf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Strategies ===\n",
      "Optimistic (point estimate):     Personalized\n",
      "Conservative (high confidence):  Popular\n",
      "Thompson Sampling:               Popular\n",
      "UCB (exploration bonus):         Personalized\n",
      "Prediction certainty:            -41.2%\n"
     ]
    }
   ],
   "source": [
    "def risk_aware_decision(uplift_mean, uplift_std, uplift_lower, \n",
    "                       threshold=0.01, confidence_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Make risk-aware treatment decisions.\n",
    "    \n",
    "    Strategies:\n",
    "    1. Optimistic: Choose if expected uplift > threshold\n",
    "    2. Conservative: Choose only if lower bound > threshold (high confidence)\n",
    "    3. Thompson Sampling: Sample from uplift distribution and choose best\n",
    "    \"\"\"\n",
    "    # Strategy 1: Optimistic (use point estimate)\n",
    "    optimistic_choice = \"Personalized\" if uplift_mean > threshold else \"Popular\"\n",
    "    \n",
    "    # Strategy 2: Conservative (require high confidence)\n",
    "    conservative_choice = \"Personalized\" if uplift_lower > threshold else \"Popular\"\n",
    "    \n",
    "    # Strategy 3: Thompson Sampling (sample from distribution)\n",
    "    uplift_sample = np.random.normal(uplift_mean, uplift_std)\n",
    "    thompson_choice = \"Personalized\" if uplift_sample > threshold else \"Popular\"\n",
    "    \n",
    "    # Strategy 4: Upper Confidence Bound (balance exploration/exploitation)\n",
    "    ucb_value = uplift_mean + 1.96 * uplift_std  # Optimistic estimate\n",
    "    ucb_choice = \"Personalized\" if ucb_value > threshold else \"Popular\"\n",
    "    \n",
    "    return {\n",
    "        'optimistic': optimistic_choice,\n",
    "        'conservative': conservative_choice,\n",
    "        'thompson_sampling': thompson_choice,\n",
    "        'ucb': ucb_choice,\n",
    "        'certainty': 1 - (uplift_std / abs(uplift_mean)) if uplift_mean != 0 else 0\n",
    "    }\n",
    "\n",
    "decisions = risk_aware_decision(uplift_mean, uplift_std, uplift_lower)\n",
    "\n",
    "print(f\"\\n=== Decision Strategies ===\")\n",
    "print(f\"Optimistic (point estimate):     {decisions['optimistic']}\")\n",
    "print(f\"Conservative (high confidence):  {decisions['conservative']}\")\n",
    "print(f\"Thompson Sampling:               {decisions['thompson_sampling']}\")\n",
    "print(f\"UCB (exploration bonus):         {decisions['ucb']}\")\n",
    "print(f\"Prediction certainty:            {decisions['certainty']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf349501",
   "metadata": {},
   "source": [
    "## Section 2.4: Use Case 2 - Multi-Treatment Personalization\n",
    "\n",
    "Choosing among 3+ treatments using Causal Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd41890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ econml not installed. Install with: pip install econml\n",
      "This demonstrates multi-treatment personalization using Causal Forests\n"
     ]
    }
   ],
   "source": [
    "# Note: This example requires econml library\n",
    "try:\n",
    "    from econml.dml import CausalForestDML\n",
    "    \n",
    "    # Create synthetic multi-treatment data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 300\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'age': np.random.randint(18, 65, n_samples),\n",
    "        'past_purchases': np.random.randint(0, 20, n_samples),\n",
    "        'treatment': np.random.choice(['discount', 'free_ship', 'bundle'], n_samples),\n",
    "        'conversion': np.random.binomial(1, 0.15, n_samples)  # Base 15% conversion\n",
    "    })\n",
    "    \n",
    "    # Train separate causal forests for each treatment vs baseline\n",
    "    treatments = ['discount', 'free_ship', 'bundle']\n",
    "    causal_models = {}\n",
    "    \n",
    "    for treatment in treatments:\n",
    "        # Create binary treatment indicator: this treatment vs all others\n",
    "        T = (data['treatment'] == treatment).astype(int)\n",
    "        X = data[['age', 'past_purchases']]\n",
    "        Y = data['conversion']\n",
    "        \n",
    "        model = CausalForestDML(\n",
    "            model_y=RandomForestRegressor(n_estimators=100),\n",
    "            model_t=RandomForestClassifier(n_estimators=100)\n",
    "        )\n",
    "        model.fit(Y, T, X=X, W=None)\n",
    "        causal_models[treatment] = model\n",
    "    \n",
    "    # Predict uplift for each treatment, choose best\n",
    "    def personalized_promotion(user_features):\n",
    "        \"\"\"Assign promotion based on predicted uplift.\"\"\"\n",
    "        uplifts = {\n",
    "            treatment: model.effect(user_features)[0]\n",
    "            for treatment, model in causal_models.items()\n",
    "        }\n",
    "        \n",
    "        best_treatment = max(uplifts, key=uplifts.get)\n",
    "        return best_treatment, uplifts\n",
    "    \n",
    "    # Example\n",
    "    user = pd.DataFrame({'age': [25], 'past_purchases': [3]})\n",
    "    treatment, all_uplifts = personalized_promotion(user)\n",
    "    print(f\"✓ Recommended treatment: {treatment}\")\n",
    "    print(f\"  Predicted uplifts: {all_uplifts}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠ econml not installed. Install with: pip install econml\")\n",
    "    print(\"This demonstrates multi-treatment personalization using Causal Forests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5fcb7",
   "metadata": {},
   "source": [
    "## Section 2.5: Use Case 3 - Model Calibration\n",
    "\n",
    "Correcting systematic biases using experiment data as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70abf228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results (Predicted vs Actual):\n",
      "   predicted_ctr  actual_ctr  is_new_user\n",
      "0           0.10        0.08            1\n",
      "1           0.08        0.07            1\n",
      "2           0.05        0.04            0\n",
      "3           0.12        0.10            1\n",
      "4           0.15        0.13            0\n",
      "\n",
      "✓ Calibration complete\n",
      "  Original prediction: 0.1000\n",
      "  Calibrated prediction: 0.0800\n",
      "  Adjustment: -0.0200\n"
     ]
    }
   ],
   "source": [
    "# Experiment data: predicted CTR vs actual CTR\n",
    "experiment_results = pd.DataFrame({\n",
    "    'predicted_ctr': [0.10, 0.08, 0.05, 0.12, 0.15],\n",
    "    'actual_ctr': [0.08, 0.07, 0.04, 0.10, 0.13],\n",
    "    'is_new_user': [1, 1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "print(\"Experiment Results (Predicted vs Actual):\")\n",
    "print(experiment_results)\n",
    "\n",
    "# Train calibrator for new users\n",
    "new_user_data = experiment_results[experiment_results['is_new_user'] == 1]\n",
    "calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "calibrator.fit(new_user_data['predicted_ctr'], new_user_data['actual_ctr'])\n",
    "\n",
    "# Apply calibration\n",
    "def calibrated_ctr_prediction(predicted_ctr, is_new_user):\n",
    "    if is_new_user:\n",
    "        return calibrator.predict([predicted_ctr])[0]\n",
    "    else:\n",
    "        return predicted_ctr  # No adjustment for existing users\n",
    "\n",
    "# Test\n",
    "test_pred = 0.10\n",
    "calibrated = calibrated_ctr_prediction(test_pred, is_new_user=True)\n",
    "print(f\"\\n✓ Calibration complete\")\n",
    "print(f\"  Original prediction: {test_pred:.4f}\")\n",
    "print(f\"  Calibrated prediction: {calibrated:.4f}\")\n",
    "print(f\"  Adjustment: {(calibrated - test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126fcfb6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **T-Learner for Binary Treatment**: Training separate models for treatment and control groups\n",
    "2. **Uncertainty Quantification**: Using Random Forest variance and bootstrap methods\n",
    "3. **Risk-Aware Decisions**: Multiple strategies (optimistic, conservative, Thompson sampling, UCB)\n",
    "4. **Multi-Treatment Personalization**: Using Causal Forests for 3+ treatments (requires econml)\n",
    "5. **Model Calibration**: Correcting systematic biases using isotonic regression\n",
    "\n",
    "All code examples are 100% consistent with Chapter 18 content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
