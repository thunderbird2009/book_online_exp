{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9a5ad8",
   "metadata": {},
   "source": [
    "# Chapter 2: The Statistical Engine of Experimentation\n",
    "\n",
    "This notebook demonstrated all key statistical tests and calculations for A/B testing:\n",
    "\n",
    "1. **Confidence Interval Calculation**: Functions to calculate CIs for both proportions and continuous metrics\n",
    "2. **Sample Size Calculation**: Determining required sample sizes for both metric types  \n",
    "3. **Z-test for Proportions**: Testing conversion rates and other binary metrics\n",
    "4. **Welch's t-test**: Testing continuous metrics like revenue without assuming equal variances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b9605",
   "metadata": {},
   "source": [
    "## Setup: Install Required Packages\n",
    "\n",
    "The following packages are required for this notebook. Uncomment and run if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103aadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install numpy scipy statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2897b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "from statsmodels.stats.power import zt_ind_solve_power, tt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportion_effectsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583713dc",
   "metadata": {},
   "source": [
    "## Section 2.3: Calculating Confidence Intervals for the Difference\n",
    "\n",
    "This section demonstrates how to calculate confidence intervals for the difference between two groups, for both proportions and continuous metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ci_for_proportions(conversions_A, n_A, conversions_B, n_B, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval for the difference in proportions (p_B - p_A).\n",
    "    \n",
    "    Args:\n",
    "        conversions_A: Number of conversions in control group\n",
    "        n_A: Total users in control group\n",
    "        conversions_B: Number of conversions in treatment group\n",
    "        n_B: Total users in treatment group\n",
    "        confidence: Confidence level (default 0.95 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (difference, lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    p_A = conversions_A / n_A\n",
    "    p_B = conversions_B / n_B\n",
    "    diff = p_B - p_A\n",
    "    \n",
    "    # Standard error of the difference\n",
    "    se_diff = np.sqrt((p_A * (1 - p_A) / n_A) + (p_B * (1 - p_B) / n_B))\n",
    "    \n",
    "    # Critical value for the confidence level\n",
    "    alpha = 1 - confidence\n",
    "    z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    # Confidence interval\n",
    "    margin_of_error = z_critical * se_diff\n",
    "    lower = diff - margin_of_error\n",
    "    upper = diff + margin_of_error\n",
    "    \n",
    "    return diff, lower, upper\n",
    "\n",
    "def calculate_ci_for_means(data_A, data_B, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval for the difference in means (mean_B - mean_A).\n",
    "    Uses Welch's approximation for unequal variances.\n",
    "    \n",
    "    Args:\n",
    "        data_A: Array of values from control group\n",
    "        data_B: Array of values from treatment group\n",
    "        confidence: Confidence level (default 0.95 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (difference, lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    mean_A = np.mean(data_A)\n",
    "    mean_B = np.mean(data_B)\n",
    "    diff = mean_B - mean_A\n",
    "    \n",
    "    # Standard errors\n",
    "    se_A = stats.sem(data_A)\n",
    "    se_B = stats.sem(data_B)\n",
    "    se_diff = np.sqrt(se_A**2 + se_B**2)\n",
    "    \n",
    "    # Degrees of freedom (Welch-Satterthwaite equation)\n",
    "    var_A = np.var(data_A, ddof=1)\n",
    "    var_B = np.var(data_B, ddof=1)\n",
    "    n_A = len(data_A)\n",
    "    n_B = len(data_B)\n",
    "    \n",
    "    df = (var_A/n_A + var_B/n_B)**2 / ((var_A/n_A)**2/(n_A-1) + (var_B/n_B)**2/(n_B-1))\n",
    "    \n",
    "    # Critical value from t-distribution\n",
    "    alpha = 1 - confidence\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "    \n",
    "    # Confidence interval\n",
    "    margin_of_error = t_critical * se_diff\n",
    "    lower = diff - margin_of_error\n",
    "    upper = diff + margin_of_error\n",
    "    \n",
    "    return diff, lower, upper\n",
    "\n",
    "# Example 1: Proportions (Conversion Rate)\n",
    "print(\"=== Confidence Interval for Conversion Rate Difference ===\")\n",
    "conversions_A = 1200  # Control\n",
    "n_A = 10000\n",
    "conversions_B = 1350  # Treatment\n",
    "n_B = 10000\n",
    "\n",
    "diff, lower, upper = calculate_ci_for_proportions(conversions_A, n_A, conversions_B, n_B)\n",
    "\n",
    "print(f\"Control conversion rate: {conversions_A/n_A:.2%}\")\n",
    "print(f\"Treatment conversion rate: {conversions_B/n_B:.2%}\")\n",
    "print(f\"Difference: {diff:.2%}\")\n",
    "print(f\"95% CI for difference: [{lower:.2%}, {upper:.2%}]\")\n",
    "\n",
    "if lower > 0:\n",
    "    print(\"Interpretation: We are 95% confident the treatment INCREASES conversion.\")\n",
    "elif upper < 0:\n",
    "    print(\"Interpretation: We are 95% confident the treatment DECREASES conversion.\")\n",
    "else:\n",
    "    print(\"Interpretation: CI includes zero - effect is not statistically significant.\")\n",
    "\n",
    "# Example 2: Continuous Metrics (Revenue)\n",
    "print(\"\\n=== Confidence Interval for Revenue Difference ===\")\n",
    "np.random.seed(42)\n",
    "revenue_A = np.random.normal(25.50, 45.20, 5000)  # Control\n",
    "revenue_B = np.random.normal(28.80, 47.10, 5000)  # Treatment\n",
    "\n",
    "diff, lower, upper = calculate_ci_for_means(revenue_A, revenue_B)\n",
    "\n",
    "print(f\"Control mean revenue: ${np.mean(revenue_A):.2f}\")\n",
    "print(f\"Treatment mean revenue: ${np.mean(revenue_B):.2f}\")\n",
    "print(f\"Difference: ${diff:.2f}\")\n",
    "print(f\"95% CI for difference: [${lower:.2f}, ${upper:.2f}]\")\n",
    "print(f\"Relative lift: {diff/np.mean(revenue_A):.1%}\")\n",
    "\n",
    "if lower > 0:\n",
    "    print(\"Interpretation: We are 95% confident the treatment INCREASES revenue.\")\n",
    "elif upper < 0:\n",
    "    print(\"Interpretation: We are 95% confident the treatment DECREASES revenue.\")\n",
    "else:\n",
    "    print(\"Interpretation: CI includes zero - effect is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e5cb3",
   "metadata": {},
   "source": [
    "## Section 3: Sample Size Calculation\n",
    "\n",
    "This section demonstrates how to calculate required sample sizes for both proportion tests and continuous metric tests using `statsmodels.stats.power`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Sample size for proportions (conversion rate test)\n",
    "# Baseline conversion rate: 12%\n",
    "# Minimum detectable effect: 1.5 percentage points (12% -> 13.5%)\n",
    "# Significance level: 0.05 (two-sided)\n",
    "# Power: 0.80\n",
    "\n",
    "baseline_rate = 0.12\n",
    "treatment_rate = 0.135\n",
    "alpha = 0.05\n",
    "power = 0.80\n",
    "\n",
    "# Calculate effect size (Cohen's h for proportions)\n",
    "effect_size = proportion_effectsize(baseline_rate, treatment_rate)\n",
    "\n",
    "# Calculate required sample size per group\n",
    "sample_size_prop = zt_ind_solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    ratio=1.0,  # Equal group sizes\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "print(\"=== Sample Size for Proportions Test ===\")\n",
    "print(f\"Baseline rate: {baseline_rate:.1%}\")\n",
    "print(f\"Target rate: {treatment_rate:.1%}\")\n",
    "print(f\"Minimum detectable effect: {(treatment_rate - baseline_rate):.1%}\")\n",
    "print(f\"Effect size (Cohen's h): {effect_size:.4f}\")\n",
    "print(f\"Required sample size per group: {int(np.ceil(sample_size_prop)):,}\")\n",
    "print(f\"Total sample size: {int(np.ceil(sample_size_prop * 2)):,}\\n\")\n",
    "\n",
    "# Example 2: Sample size for continuous metrics (ARPU test)\n",
    "# Baseline mean: $25\n",
    "# Minimum detectable effect: $3 (12% lift)\n",
    "# Pooled standard deviation: $45\n",
    "# Significance level: 0.05 (two-sided)\n",
    "# Power: 0.80\n",
    "\n",
    "baseline_mean = 25.0\n",
    "mde = 3.0  # Minimum detectable effect\n",
    "pooled_std = 45.0\n",
    "\n",
    "# Calculate standardized effect size (Cohen's d)\n",
    "cohens_d = mde / pooled_std\n",
    "\n",
    "# Calculate required sample size per group\n",
    "sample_size_cont = tt_ind_solve_power(\n",
    "    effect_size=cohens_d,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    ratio=1.0,  # Equal group sizes\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "print(\"=== Sample Size for Continuous Metrics Test ===\")\n",
    "print(f\"Baseline mean: ${baseline_mean:.2f}\")\n",
    "print(f\"Minimum detectable effect: ${mde:.2f}\")\n",
    "print(f\"Pooled standard deviation: ${pooled_std:.2f}\")\n",
    "print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "print(f\"Required sample size per group: {int(np.ceil(sample_size_cont)):,}\")\n",
    "print(f\"Total sample size: {int(np.ceil(sample_size_cont * 2)):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca91fc4",
   "metadata": {},
   "source": [
    "## Section 4.1: Z-test for Proportions\n",
    "\n",
    "This example demonstrates how to test the difference in conversion rates between a control and treatment group using a two-sample Z-test for proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df07a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing conversion rate between control and treatment\n",
    "# Control group: 1,200 conversions out of 10,000 users (12% conversion)\n",
    "# Treatment group: 1,350 conversions out of 10,000 users (13.5% conversion)\n",
    "\n",
    "conversions = np.array([1200, 1350])  # Number of conversions\n",
    "sample_sizes = np.array([10000, 10000])  # Total users in each group\n",
    "\n",
    "# Perform two-sided Z-test\n",
    "z_stat, p_value = proportions_ztest(conversions, sample_sizes, alternative='two-sided')\n",
    "\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Calculate 95% confidence interval for the difference\n",
    "# (using individual CIs for each group as an approximation)\n",
    "ci_control = proportion_confint(conversions[0], sample_sizes[0], alpha=0.05, method='normal')\n",
    "ci_treatment = proportion_confint(conversions[1], sample_sizes[1], alpha=0.05, method='normal')\n",
    "\n",
    "print(f\"\\nControl conversion rate: {conversions[0]/sample_sizes[0]:.4f}\")\n",
    "print(f\"95% CI for control: [{ci_control[0]:.4f}, {ci_control[1]:.4f}]\")\n",
    "print(f\"\\nTreatment conversion rate: {conversions[1]/sample_sizes[1]:.4f}\")\n",
    "print(f\"95% CI for treatment: [{ci_treatment[0]:.4f}, {ci_treatment[1]:.4f}]\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(f\"\\nResult: Statistically significant (p < 0.05)\")\n",
    "    print(\"We reject the null hypothesis. The treatment has a significant effect.\")\n",
    "else:\n",
    "    print(f\"\\nResult: Not statistically significant (p >= 0.05)\")\n",
    "    print(\"We fail to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76291a1",
   "metadata": {},
   "source": [
    "## Section 4.2: Welch's t-test for Continuous Metrics\n",
    "\n",
    "This example demonstrates how to test the difference in average revenue per user (ARPU) between control and treatment groups using Welch's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc81e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing average revenue per user (ARPU) between control and treatment\n",
    "# Control group: Mean = $25.50, Std = $45.20, n = 5,000\n",
    "# Treatment group: Mean = $28.80, Std = $47.10, n = 5,000\n",
    "\n",
    "# Generate sample data (in practice, this comes from your experiment data)\n",
    "np.random.seed(42)\n",
    "control_revenue = np.random.normal(loc=25.50, scale=45.20, size=5000)\n",
    "treatment_revenue = np.random.normal(loc=28.80, scale=47.10, size=5000)\n",
    "\n",
    "# Perform Welch's t-test (equal_var=False)\n",
    "t_stat, p_value = stats.ttest_ind(control_revenue, treatment_revenue, equal_var=False)\n",
    "\n",
    "# Calculate means and standard errors\n",
    "mean_control = np.mean(control_revenue)\n",
    "mean_treatment = np.mean(treatment_revenue)\n",
    "se_control = stats.sem(control_revenue)\n",
    "se_treatment = stats.sem(treatment_revenue)\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "ci_control = stats.t.interval(0.95, len(control_revenue)-1, \n",
    "                               loc=mean_control, \n",
    "                               scale=se_control)\n",
    "ci_treatment = stats.t.interval(0.95, len(treatment_revenue)-1, \n",
    "                                 loc=mean_treatment, \n",
    "                                 scale=se_treatment)\n",
    "\n",
    "print(f\"Control group mean ARPU: ${mean_control:.2f}\")\n",
    "print(f\"95% CI: [${ci_control[0]:.2f}, ${ci_control[1]:.2f}]\")\n",
    "print(f\"\\nTreatment group mean ARPU: ${mean_treatment:.2f}\")\n",
    "print(f\"95% CI: [${ci_treatment[0]:.2f}, ${ci_treatment[1]:.2f}]\")\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Calculate effect size (lift)\n",
    "lift = (mean_treatment - mean_control) / mean_control * 100\n",
    "print(f\"\\nLift: {lift:.2f}%\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(f\"\\nResult: Statistically significant (p < 0.05)\")\n",
    "    print(\"We reject the null hypothesis. The treatment has a significant effect on ARPU.\")\n",
    "else:\n",
    "    print(f\"\\nResult: Not statistically significant (p >= 0.05)\")\n",
    "    print(\"We fail to reject the null hypothesis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
